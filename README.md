# LLM Token Comparator

Compare token counts across different Large Language Model (LLM) providers â€” including OpenAI, Claude, Gemini, LLaMA, and HyperCLOVA â€” to better understand prompt cost, length, and optimization strategies.

---

## Features

- Compare token counts across multiple LLM providers
- Visualize how each model tokenizes the same input
- Estimate prompt costs (optional)
- Paste text or upload files (coming soon)
- Dark/light mode support
- Open-source and developer-ready

---

## Supported Models

| Provider     | Model(s)                  | Tokenizer Method             |
|--------------|---------------------------|-------------------------------|
| OpenAI       | GPT-3.5, GPT-4            | `tiktoken`                   |
| Anthropic    | Claude 1/2/3              | Approximate logic            |
| Google       | Gemini                    | `sentencepiece`-based        |
| Meta         | LLaMA 2 / 3               | HuggingFace tokenizer        |
| Naver CLOVA  | HyperCLOVA X (bge-m3, etc.) | Optional internal tokenizer |

---

## Getting Started

### 1. Clone the Repository

<pre>
git clone https://github.com/your-username/llm-token-comparator.git
cd llm-token-comparator
</pre>

### 2. Install Dependencies

<pre>
pip install -r requirements.txt
</pre>

### 3. Run the App

<pre>
python app.py
</pre>

Or, if you're using FastAPI:

<pre>
uvicorn app:app --reload
</pre>

---

## Docker Support (Optional)

To build and run with Docker:

<pre>
docker build -t token-comparator .
docker run -p 8000:8000 token-comparator
</pre>

---

## Project Structure

llm-token-comparator/
â”œâ”€â”€ app.py                   # Main backend logic
â”œâ”€â”€ tokenizer/               # Tokenizer wrappers
â”œâ”€â”€ static/                  # Frontend assets
â”œâ”€â”€ templates/               # UI templates (Flask/Jinja)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md

---

## ðŸ“Š Sample Output

| Model     | Token Count |
|-----------|-------------|
| GPT-4     | 244         |
| Claude 2  | 212         |
| Gemini    | 198         |
| LLaMA 3   | 232         |
| CLOVA X   | 205         |

---

## ðŸ”’ Disclaimer

This tool is for developer and research use only. Tokenizer logic may differ slightly from official APIs. Always verify against provider documentation for billing-critical cases.

---

## ðŸ¤ Contributing

Pull requests and tokenizer plugin contributions are welcome!  
Want to add a provider? Follow the `/tokenizer/` pattern and open a PR.

---

## ðŸ‘¨â€ðŸ’» Author

Built by [YJ Shin](https://github.com/IronhawkReigns)  
Computer Science student @ Georgia Tech and Naver Cloud intern.

> This tool was created to help developers better understand how LLMs tokenize input â€” essential for optimizing prompts, controlling cost, and debugging strange model behavior.
